{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b6f8f87",
   "metadata": {},
   "source": [
    "# Tracking - TensorBoard\n",
    "\n",
    "- [TensorBoard](https://www.tensorflow.org/tensorboard)\n",
    "- [MLflow](https://mlflow.org/)\n",
    "- [Weights & Biases](https://wandb.ai/)\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4251b8",
   "metadata": {},
   "source": [
    "`$ tensorboard --logdir=<path to folder>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q tensorboard torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36760f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms.v2 as T\n",
    "\n",
    "from torchmetrics.classification import Accuracy\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844c83d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c872af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToImage(),\n",
    "    T.ToDtype(torch.float32, scale=True),\n",
    "    T.ToPureTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26975337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:18<00:00, 1.40MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 107kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:04<00:00, 916kB/s] \n",
      "100%|██████████| 5.15k/5.15k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d207b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc539a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'T-shirt/top',\n",
       " 1: 'Trouser',\n",
       " 2: 'Pullover',\n",
       " 3: 'Dress',\n",
       " 4: 'Coat',\n",
       " 5: 'Sandal',\n",
       " 6: 'Shirt',\n",
       " 7: 'Sneaker',\n",
       " 8: 'Bag',\n",
       " 9: 'Ankle boot'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2class = {i: c for c, i in training_data.class_to_idx.items()}\n",
    "idx2class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0115a152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = training_data[0]\n",
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acf0dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 9)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0].shape, sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b108a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample[0].permute(1, 2, 0))\n",
    "plt.title(idx2class[sample[1]])\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d9b04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31507456",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64, drop_last=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53986d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(937, 157)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27240a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(937.5, 156.25)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60000/64, 10000/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca0b882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for batch in train_dataloader:\n",
    "    if i == 936:\n",
    "        print(batch[0].shape, batch[1].shape)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4bf7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for batch in test_dataloader:\n",
    "    if i == 156:\n",
    "        print(batch[0].shape, batch[1].shape)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e7e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.LazyLinear(10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5149879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 5\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, drop_last=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "metric_fn = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "model = ImageClassifier().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f45374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.4187 accuracy: 0.0781 [0 / 937]\n",
      "loss: 1.2694 accuracy: 0.6875 [100 / 937]\n",
      "loss: 0.7894 accuracy: 0.8438 [200 / 937]\n",
      "loss: 0.8821 accuracy: 0.7188 [300 / 937]\n",
      "loss: 0.7219 accuracy: 0.7188 [400 / 937]\n",
      "loss: 0.6614 accuracy: 0.7969 [500 / 937]\n",
      "loss: 0.6595 accuracy: 0.7500 [600 / 937]\n",
      "loss: 0.6109 accuracy: 0.8281 [700 / 937]\n",
      "loss: 0.6784 accuracy: 0.7500 [800 / 937]\n",
      "loss: 0.4550 accuracy: 0.8750 [900 / 937]\n",
      "Eval metrics: \n",
      "Accuracy: 0.8126, Avg loss: 0.5487 \n",
      "\n",
      "loss: 0.4702 accuracy: 0.8594 [0 / 937]\n",
      "loss: 0.5298 accuracy: 0.8125 [100 / 937]\n",
      "loss: 0.3712 accuracy: 0.8594 [200 / 937]\n",
      "loss: 0.5703 accuracy: 0.7812 [300 / 937]\n",
      "loss: 0.5734 accuracy: 0.7500 [400 / 937]\n",
      "loss: 0.4558 accuracy: 0.8750 [500 / 937]\n",
      "loss: 0.4781 accuracy: 0.8281 [600 / 937]\n",
      "loss: 0.5369 accuracy: 0.8125 [700 / 937]\n",
      "loss: 0.6167 accuracy: 0.7344 [800 / 937]\n",
      "loss: 0.3597 accuracy: 0.8750 [900 / 937]\n",
      "Eval metrics: \n",
      "Accuracy: 0.8382, Avg loss: 0.4645 \n",
      "\n",
      "loss: 0.3689 accuracy: 0.8750 [0 / 937]\n",
      "loss: 0.4234 accuracy: 0.8750 [100 / 937]\n",
      "loss: 0.3101 accuracy: 0.9062 [200 / 937]\n",
      "loss: 0.4869 accuracy: 0.7969 [300 / 937]\n",
      "loss: 0.5131 accuracy: 0.7188 [400 / 937]\n",
      "loss: 0.3987 accuracy: 0.8438 [500 / 937]\n",
      "loss: 0.4031 accuracy: 0.8438 [600 / 937]\n",
      "loss: 0.4987 accuracy: 0.8438 [700 / 937]\n",
      "loss: 0.5791 accuracy: 0.7812 [800 / 937]\n",
      "loss: 0.3156 accuracy: 0.8906 [900 / 937]\n",
      "Eval metrics: \n",
      "Accuracy: 0.8518, Avg loss: 0.4236 \n",
      "\n",
      "loss: 0.3202 accuracy: 0.8906 [0 / 937]\n",
      "loss: 0.3678 accuracy: 0.8906 [100 / 937]\n",
      "loss: 0.2729 accuracy: 0.9219 [200 / 937]\n",
      "loss: 0.4442 accuracy: 0.8281 [300 / 937]\n",
      "loss: 0.4696 accuracy: 0.7656 [400 / 937]\n",
      "loss: 0.3761 accuracy: 0.8438 [500 / 937]\n",
      "loss: 0.3592 accuracy: 0.8906 [600 / 937]\n",
      "loss: 0.4697 accuracy: 0.8438 [700 / 937]\n",
      "loss: 0.5442 accuracy: 0.8125 [800 / 937]\n",
      "loss: 0.2907 accuracy: 0.9219 [900 / 937]\n",
      "Eval metrics: \n",
      "Accuracy: 0.8614, Avg loss: 0.3965 \n",
      "\n",
      "loss: 0.2897 accuracy: 0.8906 [0 / 937]\n",
      "loss: 0.3341 accuracy: 0.8906 [100 / 937]\n",
      "loss: 0.2460 accuracy: 0.9219 [200 / 937]\n",
      "loss: 0.4184 accuracy: 0.8281 [300 / 937]\n",
      "loss: 0.4358 accuracy: 0.7969 [400 / 937]\n",
      "loss: 0.3667 accuracy: 0.8438 [500 / 937]\n",
      "loss: 0.3336 accuracy: 0.8906 [600 / 937]\n",
      "loss: 0.4449 accuracy: 0.8438 [700 / 937]\n",
      "loss: 0.5111 accuracy: 0.8125 [800 / 937]\n",
      "loss: 0.2741 accuracy: 0.9219 [900 / 937]\n",
      "Eval metrics: \n",
      "Accuracy: 0.8683, Avg loss: 0.3761 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "global_step = -1\n",
    "for epoch in range(num_epoch):\n",
    "    # Train\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        X, y = batch\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        accuracy = metric_fn(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            train_loss = loss.item()\n",
    "            train_accuracy = accuracy.item()\n",
    "            writer.add_scalar(\"loss\", train_loss, global_step=global_step)\n",
    "            writer.add_scalar(\"accuracy\", train_accuracy, global_step=global_step)\n",
    "            print(f\"loss: {train_loss:.4f} accuracy: {train_accuracy:.4f} [{batch_idx} / {len(train_dataloader)}]\")\n",
    "    \n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            eval_loss += loss_fn(y_pred, y).item()\n",
    "            eval_accuracy += metric_fn(y_pred, y).item()\n",
    "\n",
    "    eval_loss /= len(test_dataloader)\n",
    "    eval_accuracy /= len(test_dataloader)\n",
    "    writer.add_scalar(\"eval_loss\", eval_loss, global_step=epoch)\n",
    "    writer.add_scalar(\"eval_accuracy\", eval_accuracy, global_step=epoch)\n",
    "\n",
    "    print(f\"Eval metrics: \\nAccuracy: {eval_accuracy:.4f}, Avg loss: {eval_loss:.4f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fb65ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
